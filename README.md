
<!-- TABLE OF CONTENTS -->

<details>
<summary><h2>Table of Contents</h2></summary>
<ol>
<li>
<a href="#about-the-project">About The Project</a>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#the-goal">The Goal</a></li>
</ul>
</li>
<li>
<a href="#configuration">Configuration</a>
<ul>
<li><a href="#control-inputs-sensors">Control Inputs: Sensors</a></li>
<li><a href="#control-outputs-mobility">Control Outputs: Mobility</a></li>
</ul>
</li>
<li>
<a href="#reward-calculation">Reward Calculation</a>
<ul>
<li><a href="#algorithm">Algorithm</a></li>
<li><a href="#environment">Environment</a></li>
</ul>
</li>
<li><a href="#running-the-robot">Running the Robot</a>
<ul>
<li><a href="#usage">Usage</a></li>
<li><a href="#dependencies">Dependencies</a></li>
</ul>
</li>
<li><a href="#roadmap">Roadmap</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
<li><a href="#contact">Contact</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
</ol>
</details>

---

# About The Project

## Introduction
This project aims to develop an autonomous robot replica similar to a Roomba, designed to navigate and clean a space independently. The environment for this project was created using OpenAI's tools, primarily because OpenAI Gym provides flexibility and is not constrained to a specific development approach. Although the robot does not have many advanced features, it offers a simple framework for novice roboticists to understand the basics of robot software development, mimicking the essential functions of a real Roomba. While using an actual Roomba is always recommended, a well-crafted Python simulator serves as a more accessible starting point.

<p align="right">(<a href="#top">back to top</a>)</p>

## The Goal
The goal of the robot is straightforward: navigate to a predetermined location while cleaning as much of the space as possible (i.e., covering each area at least once). The robot uses Q-learning to make decisions that are initially random but improve over time as it learns from the rewards based on how efficiently it cleans and the time taken. Over multiple iterations, the robot will optimize its cleaning path and decision-making process.

<p align="right">(<a href="#top">back to top</a>)</p>

# Configuration

## Control Inputs: Sensors
A robot can be configured in various ways to monitor its surroundings using different sensors, including proximity sensors, cameras, light sensors, and bumpers. In this project, the robot is equipped with a simulated lidar sensor that detects obstacles by firing lasers in all directions. Additionally, four "wall sensors" are strategically placed to detect the robot's proximity to barriers.

The lidar sensor's range and precision are adjustable, and additional wall sensors can be added as needed. The robot makes the following assumptions using its proximity sensors:

- Distance to barriers
- Location of the robot
- The robot's compass direction

These sensor readings, although imperfect, are crucial for the robot's decision-making process.

<p align="right">(<a href="#top">back to top</a>)</p>

## Control Outputs: Mobility
The robot's target coordinates are input into the control program before it starts, although these could also be dynamically generated by an external Python application. The robot operates under several assumptions:

- Obstacles are never spherical, and the terrain is always flat.
- The tires do not slip.
- Nothing external moves the robot.
- Sensor readings are never entirely incorrect, though they may be imprecise.

These assumptions are generally realistic for a home-like environment, though exceptions can occur, such as circular obstacles. The robotâ€™s obstacle avoidance program is simple yet effective, allowing it to navigate around barriers by following their perimeter.

<p align="right">(<a href="#top">back to top</a>)</p>

# Reward Calculation

## Algorithm
The algorithm is designed to balance time efficiency and area cleaned. The robot is rewarded for quickly covering new, previously uncleaned areas and penalized for taking too long or revisiting already cleaned areas. This encourages the robot to avoid unnecessary revisits and focus on maximizing its cleaning efficiency.

## Environment
The environment is structured using the `observation_space` and `action_space` attributes of the Gym `Env` class:

- `observation_space`: Defines the structure and valid values of the environment's state observation, typically represented by a screenshot or vector form.
- `action_space`: Describes the numerical structure of valid actions that the robot can perform in the environment.

<p align="right">(<a href="#top">back to top</a>)</p>

# Running the Robot

## Usage
To run the program, use the following command:

```bash
[program_name] [image_location] [(x,y) origin] [(x,y) finish] [sensor_range] [sigma_noise_values from 1-5]
```

The robot will automatically begin "cleaning" the area based on the parameters provided.

<p align="right">(<a href="#top">back to top</a>)</p>

## Dependencies
Ensure that the following dependencies are installed:

- `Gym`: Required for the machine learning agent.
- `Pygame`: Provides the environment for Gym.
- `Numpy`: Used for array computations and mathematical operations.

<p align="right">(<a href="#top">back to top</a>)</p>

# Contributing

Contributions are what make the open-source community such a wonderful place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that could improve this project, please fork the repo and create a pull request. Alternatively, you can open an issue with the tag "enhancement". Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

<p align="right">(<a href="#top">back to top</a>)</p>

# License

Distributed under the MIT License. See `LICENSE.txt` for more information.

<p align="right">(<a href="#top">back to top</a>)</p>

# Contact

Your Name - [@your_twitter](https://twitter.com/your_username) - email@example.com

Project Link: [https://github.com/your_username/repo_name](https://github.com/your_username/repo_name)

<p align="right">(<a href="#top">back to top</a>)</p>

# Acknowledgments

Here are some resources that were helpful during the development of this project:

- [Choose an Open Source License](https://choosealicense.com)
- [GitHub Emoji Cheat Sheet](https://www.webpagefx.com/tools/emoji-cheat-sheet)
- [Malven's Flexbox Cheatsheet](https://flexbox.malven.co/)
- [Malven's Grid Cheatsheet](https://grid.malven.co/)
- [Img Shields](https://shields.io)
- [GitHub Pages](https://pages.github.com)
- [Font Awesome](https://fontawesome.com)
- [React Icons](https://react-icons.github.io/react-icons/search)

<p align="right">(<a href="#top">back to top</a>)</p>
